{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S0vAxKjIEqi0"
   },
   "source": [
    "# DCGAN\n",
    "\n",
    "Inspired by the course assignment for [CSC321](http://www.cs.toronto.edu/~rgrosse/courses/csc321_2018/) by Professor [Roger Grosse](http://www.cs.toronto.edu/~rgrosse/).\n",
    "\n",
    "We will implement a Deep Convolutional GAN (DCGAN) introduced by [Radford et. al, 2015](https://arxiv.org/abs/1511.06434). A DCGAN is simply a GAN that uses a convolutional neural network as the discriminator, and\n",
    "a network composed of transposed convolutions as the generator.\n",
    "\n",
    "To implement the DCGAN, we need to specify three things: \n",
    "1. The generator\n",
    "2. The discriminator, and \n",
    "3. The training procedure.\n",
    "\n",
    "We will develop each of these three components in the following subsections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2kQGYrMhEfA2"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import math\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ciqWnQcuGaEZ"
   },
   "source": [
    "# Discriminator\n",
    "\n",
    "The discriminator in this DCGAN is a convolutional neural network that has the following architecture:\n",
    "\n",
    "![Discriminator Architecture](https://imgur.com/download/A0hd29X/)\n",
    "\n",
    "Padding: In each of the convolutional layers shown above, we downsample the spatial dimension of the input volume by a factor of 2. Given that we use kernel size K = 4 and stride S = 2, what should the padding be?\n",
    "\n",
    "Complete the following function named `conv` that returns a Convolutional block according to the above schematic (Convolution followed by a BatchNorm followed by an Activation). The function takes an argument `x` which is the input tensor to the block, number of out-channels `c_out`. A `LeakyReLU` activation, with the slope of the leak set to `0.2` as mentioned in [Radford et. al., 2015](https://arxiv.org/abs/1511.06434), should be added to the block (we will use `LeakyReLU` even though the diagram mentions `ReLU`). There is a `weight_init` argument, which is \n",
    "an [initializer](https://www.tensorflow.org/api_docs/python/tf/keras/initializers) object. It should be used to initialize the weights of the Convolutional layer in the block. \n",
    "\n",
    "The Convolutional layer should **not** have `bias` units.\n",
    "\n",
    "Hint: Use the [Functional API](https://www.tensorflow.org/guide/keras/functional)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JRHGZAHyJAKv"
   },
   "outputs": [],
   "source": [
    "def conv(x, c_out, weight_init):\n",
    "\n",
    "  # your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sAn3UqyUMy-_"
   },
   "source": [
    "Complete the following lines for the discriminator architecture `D` as shown in the schematic (shown again for reference). The `Input` layer expects an image of `32x32` with a single channel, followed by three convolutional blocks, and a final convolutional layer. The intermediate layer activations are `LeakyReLU`s. Use [He Uniform](https://www.tensorflow.org/api_docs/python/tf/keras/initializers/he_uniform) initializer for the convolutional layer in every block.\n",
    "\n",
    "Use your implementation of the `conv` function from above for the three blocks.\n",
    "\n",
    "Create a convolutional layer at the end (it should not have bias units and uses the [He Uniform](https://www.tensorflow.org/api_docs/python/tf/keras/initializers/he_uniform) intializer). Choose appropriate kernel size and stride so that the resulting dimensions of each element in the batch are `1x1x1`. Finally, flatten the output so that output shape is `(batch_size, 1)`. The diagram shows a cube of `1x1x1`, but we will have to flatten it sooner or later, so let's do it here. The final activation is `Sigmoid`.\n",
    "\n",
    "![Discriminator Architecture](https://imgur.com/download/A0hd29X/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DN2mMDjsLtWe"
   },
   "outputs": [],
   "source": [
    "# Complete the following code statements\n",
    "\n",
    "input_image = Input(shape=(...))\n",
    "d_block = conv(...)\n",
    "d_block = conv(...)\n",
    "d_block = conv(...)\n",
    "d_block = ## complete the remaining portion\n",
    "## ...\n",
    "\n",
    "D = ## create the discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-8K6gNbkQSco"
   },
   "outputs": [],
   "source": [
    "D.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "haFcYeBdXhVQ"
   },
   "source": [
    "# Generator\n",
    "\n",
    "Now, we will implement the generator of the DCGAN, which consists of a sequence of transpose convolutional layers that progressively upsample the input noise sample to generate a fake image. The generator weâ€™ll use in this DCGAN has the following architecture:\n",
    "\n",
    "![Generator Architecture](https://imgur.com/download/jbmaWCV/)\n",
    "\n",
    "If you need a refresher on tranpose convolutions, [this](https://arxiv.org/pdf/1603.07285.pdf) is a good resource.\n",
    "\n",
    "Complete the following function named `deconv` that creates a block containing Conv2DTranspose followed by BatchNorm followed by Activation. The function takes the argument `x` which is the input tensor to the block, uses `Conv2DTranspose` layer (depicted as `deconv` layers in the schematic) to upscale the input. `Conv2DTranspose` upscales the input by a factor of 2. Use a kernel size size of 4 and pass appropriate stride value in the argument `stride`. The number of output channels is `c_out`. \n",
    "\n",
    "A `LeakyReLU` activation (with the slope of the leak set to `0.2`, in accordance with [Radford et. al., 2015](https://arxiv.org/abs/1511.06434)) should be added to the block (we will use `LeakyReLU` even though the diagram mentions `ReLU`). There is a `weight_init` argument, which is \n",
    "an [initializer](https://www.tensorflow.org/api_docs/python/tf/keras/initializers) object. It should be used to initialize the weights of the `Conv2DTranspose` layer in the block. \n",
    "\n",
    "The `Conv2DTranspose` layer should **not** have `bias` units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vlHBmV82V9jh"
   },
   "outputs": [],
   "source": [
    "def deconv(x, stride, c_out, weight_init):\n",
    "  # your code here \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CTKs1VymcL51"
   },
   "source": [
    "Complete the following lines for the generator architecture `G` as shown in the schematic (shown again for reference). The `Input` layer expects a batch of vectors of size `1x1xz_dim`.  followed by three deconv blocks, and a final `Conv2DTranspose` layer. The intermediate layer activations are `LeakyReLU`s. Use [He Uniform](https://www.tensorflow.org/api_docs/python/tf/keras/initializers/he_uniform) initializer for the tranpose convolution layer in every block.\n",
    "\n",
    "Use your implementation of the `deconv` function from above for the three blocks.\n",
    "\n",
    "Create a `Conv2DTranspose` layer at the end (it should not have bias units and uses the [He Uniform](https://www.tensorflow.org/api_docs/python/tf/keras/initializers/he_uniform) intializer). Choose appropriate kernel size and stride so that the resulting dimensions of every element in the batch are `32x32x1`. The final activation is `Tanh`.\n",
    "\n",
    "![Generator Architecture](https://imgur.com/download/jbmaWCV/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "619owMoIb_Py"
   },
   "outputs": [],
   "source": [
    "z_dim = 100\n",
    "\n",
    "# Complete the following code statements\n",
    "\n",
    "input_noise = Input(shape=(...))\n",
    "g_block = deconv(...)\n",
    "g_block = deconv(...)\n",
    "g_block = deconv(...)\n",
    "g_block = # complete the remaining portion \n",
    "## ...\n",
    "\n",
    "G = ## create the generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TWGID8zhebk3"
   },
   "outputs": [],
   "source": [
    "G.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "shj5Zsh1fRwm"
   },
   "source": [
    "# Helpers\n",
    "\n",
    "Let's write some helper functions that would aid us in training GANs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s_Ri-wXffpe-"
   },
   "source": [
    "This helper is going to help us plot images in a grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mCRu62F6fGNd"
   },
   "outputs": [],
   "source": [
    "# This function has been implemented for you. No modifications required\n",
    "\n",
    "def plot_grid(images, rows, cols, figsize=(10, 10)):\n",
    "    sample_ids = np.random.randint(0, images.shape[0], size=rows*cols)\n",
    "    sample = images[sample_ids]\n",
    "    sample = sample.squeeze(axis=-1)\n",
    "    f, ax_arr = plt.subplots(rows, cols, figsize=figsize)\n",
    "    plt.set_cmap(plt.cm.Greys_r)\n",
    "    index = 0\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            ax_arr[i, j].imshow(sample[index])\n",
    "            ax_arr[i, j].axis('off')\n",
    "            index +=1\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fvGlap-AgX8N"
   },
   "source": [
    "The following helper function returns a batch of real images \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VoiC1lT6geg7"
   },
   "outputs": [],
   "source": [
    "# This function has been implemented for you. No modifications required\n",
    "\n",
    "def get_real_batch(data, batch_id, shuffle, batch_size):\n",
    "    start_idx = int(batch_id * batch_size)\n",
    "    end_idx = int((batch_id + 1) * batch_size)\n",
    "    indices = shuffle[start_idx:end_idx]\n",
    "    num_samples = indices.shape[0]\n",
    "    return data[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2cMtO-cPoHou"
   },
   "source": [
    "Write a function to fetch a batch of fake images of size `num_images`. Sample noise from a uniform distribution in the range `[-1, 1]`. `generator` is the GAN generator, z_dim is the dimension of noise vector that the generator expects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u2gZ_8uInLsj"
   },
   "outputs": [],
   "source": [
    "def get_fake_batch(generator, z_dim, num_images):\n",
    "    ## your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u6jsOJRff43W"
   },
   "source": [
    "# Load the MNIST training dataset\n",
    "Load the MNIST dataset using TensorFlow's `tensorflow.keras.datasets.mnist` module. You will get both training and test sets. We will discard the test set, and go ahead with the training set.  \n",
    "\n",
    "You will need to do the following changes in order to get things to work:\n",
    "\n",
    "1. The images are of size `28x28`. However, out discriminator expects spatial dimensions of the image to be `32x32`. In order to make sizes match do a zero-padding using [numpy.pad](https://numpy.org/doc/1.18/reference/generated/numpy.pad.html) such that the images become `32x32`.  \n",
    "2. The images are of shape `32x32`, but the discriminator expects images of dimensions `32x32x1`. Add the channel dimension to the images. \n",
    "3. Finally, normalize the images from `[0, 255]` to `[-1, 1]` as our generator network has a Tanh output activation layer.\n",
    "\n",
    "Stored the normalized images in a variable `x_train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ln6Vi5KFftWS"
   },
   "outputs": [],
   "source": [
    "## Load MNIST data here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j9DeBfk6gNoO"
   },
   "outputs": [],
   "source": [
    "# Plot loaded data to see if everything is fine \n",
    "plot_grid(x_train, 6, 6, figsize=(6, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tDDB59sepoKY"
   },
   "source": [
    "# Hyperparamters\n",
    "\n",
    "Let's set the hyperparameters for training. We will use `Adam` optimizer with a learning rate of ` 0.0002` and `beta_1=0.5`, as mentioned in [Radford et. al., 2015](https://arxiv.org/abs/1511.06434). Pick an appropriate loss function for calculating the minmax loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-6k2TxiOgQTy"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "batch_size_half = 16\n",
    "epochs = 10  # feel free to play with the number of epochs\n",
    "\n",
    "# Total number of batches that the training set can be divided into\n",
    "n_batches = math.floor(data_size / batch_size_half)\n",
    "\n",
    "optim_d = Adam(0.0002, beta_1=0.5)\n",
    "optim_g = Adam(0.0002, beta_1=0.5)\n",
    "\n",
    "\n",
    "criterion = ## choose an appropriate loss function for calculating GAN loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PXdQlvLop3Sx"
   },
   "outputs": [],
   "source": [
    "shuffle = np.arange(data_size)\n",
    "\n",
    "for ep in range(epochs):\n",
    "    np.random.shuffle(shuffle)\n",
    "    \n",
    "    for batch_id in tqdm(range(n_batches)):\n",
    "        # Train the discriminator\n",
    "        \n",
    "        # Train the generator \n",
    "    \n",
    "    # Plot generated images after every epoch\n",
    "    print('Epoch', ep + 1, ' out of', epochs, ' done !!!')\n",
    "    rand_imgs = # generate 36 random images\n",
    "    plot_grid(rand_imgs, 6, 6, figsize=(6, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oNJoWA090WrH"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NZxXXgm8uaLo"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DCGAN_Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
